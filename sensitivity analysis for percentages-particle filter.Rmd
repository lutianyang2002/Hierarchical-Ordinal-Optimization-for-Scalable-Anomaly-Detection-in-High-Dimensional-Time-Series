---
title: "sensitivity analysis for percentages-particle filter"
author: "Joshua Lu"
output: html_document
---

```{r, echo=TRUE, warning=FALSE, message=FALSE}
file_path <- "Synthetic_High-Dimensional_Time_Series_Data.csv"
time_series_data <- read.csv(file_path)
result <- as.numeric(time_series_data$Result)  # target series used by the PF
true_anomalies <- c(8, 92, 122, 127, 130, 149, 150, 159, 164, 196)

# Coarse-grained model function
pf_coarse <- function(num_particles, sigma_process, sigma_measure,
                      threshold_percentile, num_trials, output_percent = 0.1) {
  anomaly_scores <- rep(0, length(result))
  for (trial in 1:num_trials) {
    particles <- rnorm(num_particles, mean = result[1], sd = sigma_process)
    weights <- rep(1 / num_particles, num_particles)
    for (t in 2:length(result)) {
      # Prediction step (state transition)
      particles <- particles + rnorm(num_particles, mean = 0, sd = sigma_process)

      # Measurement update (likelihood)
      likelihood <- dnorm(result[t], mean = particles, sd = sigma_measure)
      weights <- weights * likelihood
      weights <- weights / sum(weights)

      # Estimated state as weighted mean
      estimate <- sum(particles * weights)

      # Accumulate absolute error as anomaly score
      anomaly_scores[t] <- anomaly_scores[t] + abs(result[t] - estimate)

      # Resampling step
      indices <- sample(1:num_particles, size = num_particles, replace = TRUE, prob = weights)
      particles <- particles[indices]
      weights <- rep(1 / num_particles, num_particles)
    }
  }

  # Average anomaly scores across trials
  anomaly_scores <- anomaly_scores / num_trials

  top_k <- round(output_percent * length(result)) 
  return(order(anomaly_scores, decreasing = TRUE)[1:top_k])
}

# Fine-grained model function
pf_fine <- function(num_particles, sigma_process, sigma_measure,
                    threshold_percentile, num_trials, count, result) {
  anomaly_scores <- rep(0, length(result))
  for (trial in 1:num_trials) {
    particles <- rnorm(num_particles, mean = result[1], sd = sigma_process)
    weights <- rep(1 / num_particles, num_particles)

    # Sequential state update over time
    for (t in 2:length(result)) {
      # Prediction step
      particles <- particles + rnorm(num_particles, mean = 0, sd = sigma_process)

      # Measurement update
      likelihood <- dnorm(result[t], mean = particles, sd = sigma_measure)
      weights <- weights * likelihood
      weights <- weights / sum(weights)

      # Estimated state (weighted mean)
      estimate <- sum(particles * weights)

      # Accumulate absolute error as anomaly score (ONLY for indices in 'count')
      if (t %in% count) {
        anomaly_scores[t] <- anomaly_scores[t] + abs(result[t] - estimate)
      }

      # Resampling step
      indices <- sample(1:num_particles, size = num_particles, replace = TRUE, prob = weights)
      particles <- particles[indices]
      weights <- rep(1 / num_particles, num_particles)
    }
  }

  # Average scores across trials
  anomaly_scores <- anomaly_scores / num_trials
  filtered_scores <- anomaly_scores[count]
  top_indices <- order(filtered_scores, decreasing = TRUE)[1:10]
  return(count[top_indices])
}
```



Two-stage Particle Filter anomaly detection:
```{r, echo=TRUE, warning=FALSE, message=FALSE}
pf_two_stage <- function(true_anomalies,
                         detection_percent_coarse,
                         final_percent_coarse,
                         detection_percent_fine,
                         # default coarse hyperparams
                         coarse_num_particles = 3500,
                         coarse_sigma_process = 0.55,
                         coarse_sigma_measure = 0.65,
                         coarse_num_trials = 100,
                         # default fine hyperparams
                         fine_num_particles = 9500,
                         fine_sigma_process = 0.45,
                         fine_sigma_measure = 0.88,
                         fine_num_trials = 1000) {

  # Step 1: Coarse stage
  coarse_candidates <- pf_coarse(
    num_particles = coarse_num_particles,
    sigma_process = coarse_sigma_process,
    sigma_measure = coarse_sigma_measure,
    threshold_percentile = detection_percent_coarse,
    num_trials = coarse_num_trials,
    output_percent = final_percent_coarse
  )

  # Step 2: Fine stage
  fine_top_indices <- pf_fine(
    num_particles = fine_num_particles,
    sigma_process = fine_sigma_process,
    sigma_measure = fine_sigma_measure,
    threshold_percentile = detection_percent_fine,
    num_trials = fine_num_trials,
    count = coarse_candidates,
    result = result
  )

  # Step 3: Compute precision
  tp <- sum(fine_top_indices %in% true_anomalies)
  precision <- tp / length(fine_top_indices)

  # Step 4: Compute coarse recall
  tp_coarse <- sum(coarse_candidates %in% true_anomalies)
  recall_coarse <- tp_coarse / length(true_anomalies)

  # Step 5: Return both metrics
  return(list(
    precision = precision,
    recall_coarse = recall_coarse
  ))
}
```




sensitivity analysis: 
```{r, echo=TRUE, warning=FALSE, message=FALSE}
# true anomalies
true_anomalies <- c(8, 92, 122, 127, 130, 149, 150, 159, 164, 196)

# coarse model detection percentile sensitivity
coarse_percentiles <- c(0.8, 0.85, 0.90)
coarse_percentile_results <- list()
for (p in coarse_percentiles) {
  cat("Running coarse detection_percent =", p, "\n")
  coarse_percentile_results[[as.character(p)]] <-
    pf_two_stage(
      true_anomalies = true_anomalies,
      detection_percent_coarse = p,
      final_percent_coarse = 0.10,
      detection_percent_fine = 0.90
    )
}
cat("\n--- Coarse Model Detection Percentile Sensitivity ---\n")
print(coarse_percentile_results)
cat("\n")

# coarse model final output percentage sensitivity
coarse_final_percents <- c(0.05, 0.10, 0.15)
coarse_final_results <- list()
for (fp in coarse_final_percents) {
  cat("Running coarse final_percent =", fp, "\n")
  coarse_final_results[[as.character(fp)]] <-
    pf_two_stage(
      true_anomalies = true_anomalies,
      detection_percent_coarse = 0.85,
      final_percent_coarse = fp,
      detection_percent_fine = 0.90
    )
}
cat("\n--- Coarse Model Final Output Percent Sensitivity ---\n")
print(coarse_final_results)
cat("\n")

# fine model detection percentile sensitivity
fine_percentiles <- c(0.85, 0.90, 0.95)
fine_percentile_results <- list()
for (p in fine_percentiles) {
  cat("Running fine detection_percent =", p, "\n")
  fine_percentile_results[[as.character(p)]] <-
    pf_two_stage(
      true_anomalies = true_anomalies,
      detection_percent_coarse = 0.85,
      final_percent_coarse = 0.10,
      detection_percent_fine = p
    )
}
cat("\n--- Fine Model Detection Percentile Sensitivity ---\n")
print(fine_percentile_results)
cat("\n")

# summary table
sensitivity_summary <- data.frame(
  Setting = c(rep("Coarse Detection Percentile", length(coarse_percentiles)),
              rep("Coarse Final Output Percent", length(coarse_final_percents)),
              rep("Fine Detection Percentile", length(fine_percentiles))),
  Value = c(coarse_percentiles, coarse_final_percents, fine_percentiles),
  Precision = c(
    sapply(coarse_percentile_results, function(x) x$precision),
    sapply(coarse_final_results, function(x) x$precision),
    sapply(fine_percentile_results, function(x) x$precision)
  ),
  Recall = c(
    sapply(coarse_percentile_results, function(x) x$recall_coarse),
    sapply(coarse_final_results, function(x) x$recall_coarse),
    sapply(fine_percentile_results, function(x) x$recall_coarse)
  )
)
print(sensitivity_summary)
```

